---
title: Summary of Michigan DL4CV Lecture 8
date: 2022-03-30 18:27:00 +0900
category: lecture-summary
tags: michigan dl4cv
---

*ë¯¸ì‹œê°„ëŒ€í•™êµ ì»´í“¨í„° ë¹„ì „ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ (Deep Learning for Computer Vision) ì˜ 8ê°• CNN êµ¬ì¡°ë¥¼ ë“£ê³  ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.*

- **CNNì˜ êµ¬ì„± ìš”ì†Œë“¤**ì„ ì–´ë–»ê²Œ ì¡°í•©í•  ê²ƒì¸ê°€?
    - e.g. convolutional layers, pooling layers, fully-connected layers, activation functions, normalization, etc.
- ImageNet Classification Challengeë¥¼ ê¸°ì¤€ìœ¼ë¡œ CNN êµ¬ì¡°ì˜ ë°œì „ ê³¼ì •ì„ ì‚´í´ë³´ì.
    1. **AlexNet**
        - ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ë¥¼ ë„ì…í•˜ì—¬ í•´ë‹¹ ëŒ€íšŒë¥¼ ìš°ìŠ¹í•œ ì²« ë²ˆì§¸ ì‚¬ë¡€
        - ì´ 8ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë¨
    2. **ZFNet**
        - ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì³ AlextNetë³´ë‹¤ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ê°œë°œí•¨
    3. **VGGNet**
        - ì´ì „ì—ëŠ” í•„í„°ì˜ í¬ê¸°ì™€ ê°œìˆ˜, ë ˆì´ì–´ì˜ êµ¬ì„± ë“±ì„ ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì³ ì§ì ‘ ì„ íƒí•´ì•¼ í–ˆë‹¤.
        - ë ˆì´ì–´ë³„ íŠ¹ì„±ì„ íŒŒì•…í•˜ì—¬ ì¼ì¢…ì˜ ë””ìì¸ ê·œì¹™ì„ ì •ë¦¬í–ˆë‹¤.
            - convolutional layer - 3x3 stride 1 pad 1
            - max-pool layer - 2x2 stride 2
            - double #channels after pooling
    4. **GoogLeNet**
        - íš¨ìœ¨ì ì¸ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•˜ëŠ” ê²ƒì— ì´ˆì ì„ ë‘ì—ˆë‹¤.
        - stem network - ë°ì´í„°ë¥¼ ì´ˆë°˜ì— ê°•í•˜ê²Œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ì—¬ ì—°ì‚°ëŸ‰ì„ ì¤„ì˜€ë‹¤.
        - inception module - ì„œë¡œ ë‹¤ë¥¸ ì»¤ë„ í¬ê¸°ë¥¼ ê°€ì§„ convolutional layerì™€ max-pool layerë¥¼ ë³‘ë ¬ì ìœ¼ë¡œ ë‘ì—ˆë‹¤.
        - ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ì˜ ë§ˆì§€ë§‰ì— fully-connected layer ëŒ€ì‹  global average pooling layerë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì‚°ëŸ‰ì„ ì¤„ì˜€ë‹¤.
        - ë„¤íŠ¸ì›Œí¬ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ì˜ ì „ë‹¬ì´ ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤. auxiliary classifierë¥¼ ë‘ì–´ ì¤‘ê°„ì—ì„œ ì†ì‹¤ê³¼ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ê³  ì „ë‹¬í•˜ì˜€ë‹¤.
    5. **ResNet**
        - ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ í•™ìŠµì„ ì‹œí‚¤ê¸° ì–´ë ¤ì› ë‹¤.
        - ë ˆì´ì–´ ê°„ì— skip-connectionì„ ë‘ì–´ residual blockì„ êµ¬ì„±í•˜ì˜€ë‹¤. ì´ë¡œ ì¸í•´ í•­ë“± í•¨ìˆ˜ë¥¼ ì˜ í•™ìŠµí•´ë‚¼ ìˆ˜ ìˆì—ˆìœ¼ë©°, ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì˜ ì „ë‹¬í•  ìˆ˜ ìˆì—ˆë‹¤.
        - ë¬´ë ¤ 152ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆì—ˆë‹¤.
        - GoogLeNetê³¼ ê°™ì´ ì´ˆë°˜ì— ê°•í•˜ê²Œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ê³  ë§ˆì§€ë§‰ì—ëŠ” global average poolingì„ ì‚¬ìš©í•˜ì˜€ë‹¤.
- ì´í›„ ê°œì„ ëœ ëª¨ë¸ë“¤: ResNeXt,  SENet, DenseNet, MobileNet, etc.
- Neural architecture searchì™€ ê°™ì´ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ ë””ìì¸ì„ ìë™í™”í•˜ë ¤ëŠ” ì‹œë„ë„ ë‚˜íƒ€ë‚¬ë‹¤.

<aside>
ğŸ’¡ <b>Which architecture should I use?</b><br>
Donâ€™t be a hero. For most problems you should use an off-the-shelf architecture; donâ€™t try to design your own!
1. If you just care about accuracy, ResNet-50 or ResNet-101 are great choices.
2. If you want an efficient network (real-time, run on mobile, etc) try MobileNets and ShuffleNets.

</aside>

- ì°¸ê³  ìë£Œ
    - Slides and videos from Michigan EECS 498-007 / 598-005 Deep Learning for Computer Vision (Fall 2019) by Justin Johnson [[Link]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/)